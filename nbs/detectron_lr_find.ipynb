{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lr_find for detectron\n",
    "\n",
    "    0. pip install torch-lr-finder\n",
    "    1. Create a config file \n",
    "    2. Create a trainer object from this config file\n",
    "        - Trying to put this step into the method causes errors with the rcnn component registry (specifically the rcnn components I make in train.py), maybe this would be fixed by moving those to a separate file?\n",
    "    3. Instantiate a COCOLRFinder and run range_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hackathon.train import get_training_config\n",
    "from hackathon.lr_find import COCOLRFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"frcnn-r101\"\n",
    "data_dir = \"../data/hackathon\"\n",
    "configs_dir = \"../lib/detectron2/configs\"\n",
    "device = \"cuda\"\n",
    "num_gpus = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_imgs 10322\n",
      "\u001b[32m[11/20 22:47:59 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
      "\u001b[32m[11/20 22:48:00 detectron2]: \u001b[0mEnvironment info:\n",
      "----------------------  ---------------------------------------------------------------------------------------\n",
      "sys.platform            linux\n",
      "Python                  3.7.9 (default, Aug 31 2020, 12:42:55) [GCC 7.3.0]\n",
      "numpy                   1.19.1\n",
      "detectron2              0.2.1 @/home/ubuntu/anaconda3/envs/aifish/lib/python3.7/site-packages/detectron2\n",
      "Compiler                GCC 7.3\n",
      "CUDA compiler           CUDA 10.1\n",
      "detectron2 arch flags   sm_35, sm_37, sm_50, sm_52, sm_60, sm_61, sm_70, sm_75\n",
      "DETECTRON2_ENV_MODULE   <not set>\n",
      "PyTorch                 1.6.0+cu101 @/home/ubuntu/anaconda3/envs/aifish/lib/python3.7/site-packages/torch\n",
      "PyTorch debug build     False\n",
      "GPU available           True\n",
      "GPU 0                   Tesla V100-SXM2-16GB\n",
      "CUDA_HOME               /usr/local/cuda\n",
      "Pillow                  7.2.0\n",
      "torchvision             0.7.0+cu101 @/home/ubuntu/anaconda3/envs/aifish/lib/python3.7/site-packages/torchvision\n",
      "torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75\n",
      "fvcore                  0.1.2.post20200910\n",
      "cv2                     4.4.0\n",
      "----------------------  ---------------------------------------------------------------------------------------\n",
      "PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 10.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n",
      "\u001b[32m[11/20 22:48:00 detectron2]: \u001b[0mCommand line arguments: {}\n",
      "\u001b[32m[11/20 22:48:00 detectron2]: \u001b[0mRunning with full config:\n",
      "CUDNN_BENCHMARK: False\n",
      "DATALOADER:\n",
      "  ASPECT_RATIO_GROUPING: True\n",
      "  FILTER_EMPTY_ANNOTATIONS: False\n",
      "  NUM_WORKERS: 2\n",
      "  REPEAT_THRESHOLD: 0.0\n",
      "  SAMPLER_TRAIN: TrainingSampler\n",
      "DATASETS:\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
      "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
      "  PROPOSAL_FILES_TEST: ()\n",
      "  PROPOSAL_FILES_TRAIN: ()\n",
      "  TEST: ('lehi1', 'gindai2', 'onaga1')\n",
      "  TRAIN: ('ehu', 'gindai3', 'lehi', 'lehi2', 'onaga2', 'onaga3', 'mouss_seq0', 'mouss_seq1', 'afsc_seq0', 'mbari_seq0', 'JRS_1', 'JRS_2', 'JRS_3', 'JRS_4', 'JRS_5', 'JRS_6', 'JRS_7', 'JRS_8')\n",
      "GLOBAL:\n",
      "  HACK: 1.0\n",
      "INPUT:\n",
      "  CROP:\n",
      "    ENABLED: False\n",
      "    SIZE: [0.9, 0.9]\n",
      "    TYPE: relative_range\n",
      "  FORMAT: BGR\n",
      "  MASK_FORMAT: polygon\n",
      "  MAX_SIZE_TEST: 1333\n",
      "  MAX_SIZE_TRAIN: 1333\n",
      "  MIN_SIZE_TEST: 800\n",
      "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
      "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
      "MODEL:\n",
      "  ANCHOR_GENERATOR:\n",
      "    ANGLES: [[-90, 0, 90]]\n",
      "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
      "    NAME: DefaultAnchorGenerator\n",
      "    OFFSET: 0.0\n",
      "    SIZES: [[32], [64], [128], [256], [512]]\n",
      "  BACKBONE:\n",
      "    FREEZE_AT: 2\n",
      "    NAME: build_resnet_fpn_backbone\n",
      "  DEVICE: cuda\n",
      "  FPN:\n",
      "    FUSE_TYPE: sum\n",
      "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    NORM: \n",
      "    OUT_CHANNELS: 256\n",
      "  KEYPOINT_ON: False\n",
      "  LOAD_PROPOSALS: False\n",
      "  MASK_ON: False\n",
      "  META_ARCHITECTURE: GeneralizedRCNN\n",
      "  PANOPTIC_FPN:\n",
      "    COMBINE:\n",
      "      ENABLED: True\n",
      "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
      "      OVERLAP_THRESH: 0.5\n",
      "      STUFF_AREA_LIMIT: 4096\n",
      "    INSTANCE_LOSS_WEIGHT: 1.0\n",
      "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
      "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
      "  PROPOSAL_GENERATOR:\n",
      "    MIN_SIZE: 0\n",
      "    NAME: RPN\n",
      "  RESNETS:\n",
      "    DEFORM_MODULATED: False\n",
      "    DEFORM_NUM_GROUPS: 1\n",
      "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
      "    DEPTH: 101\n",
      "    NORM: FrozenBN\n",
      "    NUM_GROUPS: 1\n",
      "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
      "    RES2_OUT_CHANNELS: 256\n",
      "    RES5_DILATION: 1\n",
      "    STEM_OUT_CHANNELS: 64\n",
      "    STRIDE_IN_1X1: True\n",
      "    WIDTH_PER_GROUP: 64\n",
      "  RETINANET:\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    FOCAL_LOSS_ALPHA: 0.25\n",
      "    FOCAL_LOSS_GAMMA: 2.0\n",
      "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.4, 0.5]\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 1\n",
      "    NUM_CONVS: 4\n",
      "    PRIOR_PROB: 0.01\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "    SMOOTH_L1_LOSS_BETA: 0.1\n",
      "    TOPK_CANDIDATES_TEST: 1000\n",
      "  ROI_BOX_CASCADE_HEAD:\n",
      "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
      "    IOUS: (0.5, 0.6, 0.7)\n",
      "  ROI_BOX_HEAD:\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
      "    CLS_AGNOSTIC_BBOX_REG: False\n",
      "    CONV_DIM: 256\n",
      "    FC_DIM: 1024\n",
      "    NAME: FastRCNNConvFCHead\n",
      "    NORM: \n",
      "    NUM_CONV: 0\n",
      "    NUM_FC: 2\n",
      "    POOLER_RESOLUTION: 7\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "    TRAIN_ON_PRED_BOXES: False\n",
      "  ROI_HEADS:\n",
      "    BATCH_SIZE_PER_IMAGE: 512\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    IOU_LABELS: [0, 1]\n",
      "    IOU_THRESHOLDS: [0.5]\n",
      "    NAME: StandardROIHeads\n",
      "    NMS_THRESH_TEST: 0.5\n",
      "    NUM_CLASSES: 1\n",
      "    POSITIVE_FRACTION: 0.25\n",
      "    PROPOSAL_APPEND_GT: True\n",
      "    SCORE_THRESH_TEST: 0.05\n",
      "  ROI_KEYPOINT_HEAD:\n",
      "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
      "    NAME: KRCNNConvDeconvUpsampleHead\n",
      "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
      "    NUM_KEYPOINTS: 17\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  ROI_MASK_HEAD:\n",
      "    CLS_AGNOSTIC_MASK: False\n",
      "    CONV_DIM: 256\n",
      "    NAME: MaskRCNNConvUpsampleHead\n",
      "    NORM: \n",
      "    NUM_CONV: 4\n",
      "    POOLER_RESOLUTION: 14\n",
      "    POOLER_SAMPLING_RATIO: 0\n",
      "    POOLER_TYPE: ROIAlignV2\n",
      "  RPN:\n",
      "    BATCH_SIZE_PER_IMAGE: 256\n",
      "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
      "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
      "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
      "    BOUNDARY_THRESH: -1\n",
      "    HEAD_NAME: StandardRPNHead\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
      "    IOU_LABELS: [0, -1, 1]\n",
      "    IOU_THRESHOLDS: [0.3, 0.7]\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NMS_THRESH: 0.7\n",
      "    POSITIVE_FRACTION: 0.5\n",
      "    POST_NMS_TOPK_TEST: 1000\n",
      "    POST_NMS_TOPK_TRAIN: 1000\n",
      "    PRE_NMS_TOPK_TEST: 1000\n",
      "    PRE_NMS_TOPK_TRAIN: 2000\n",
      "    SMOOTH_L1_BETA: 0.0\n",
      "  SEM_SEG_HEAD:\n",
      "    COMMON_STRIDE: 4\n",
      "    CONVS_DIM: 128\n",
      "    IGNORE_VALUE: 255\n",
      "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
      "    LOSS_WEIGHT: 1.0\n",
      "    NAME: SemSegFPNHead\n",
      "    NORM: GN\n",
      "    NUM_CLASSES: 54\n",
      "  WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl\n",
      "OUTPUT_DIR: ./outputfrcnn-r101\n",
      "SEED: 42\n",
      "SOLVER:\n",
      "  BASE_LR: 0.0025\n",
      "  BIAS_LR_FACTOR: 1.0\n",
      "  CHECKPOINT_PERIOD: 5160\n",
      "  CLIP_GRADIENTS:\n",
      "    CLIP_TYPE: value\n",
      "    CLIP_VALUE: 1.0\n",
      "    ENABLED: False\n",
      "    NORM_TYPE: 2.0\n",
      "  GAMMA: 0.1\n",
      "  IMS_PER_BATCH: 2\n",
      "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
      "  MAX_ITER: 92898\n",
      "  MOMENTUM: 0.9\n",
      "  NESTEROV: False\n",
      "  REFERENCE_WORLD_SIZE: 0\n",
      "  STEPS: (61932, 82576)\n",
      "  WARMUP_FACTOR: 0.001\n",
      "  WARMUP_ITERS: 1000\n",
      "  WARMUP_METHOD: linear\n",
      "  WEIGHT_DECAY: 0.0001\n",
      "  WEIGHT_DECAY_BIAS: 0.0001\n",
      "  WEIGHT_DECAY_NORM: 0.0\n",
      "TEST:\n",
      "  AUG:\n",
      "    ENABLED: False\n",
      "    FLIP: True\n",
      "    MAX_SIZE: 4000\n",
      "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
      "  DETECTIONS_PER_IMAGE: 100\n",
      "  EVAL_PERIOD: 5160\n",
      "  EXPECTED_RESULTS: []\n",
      "  KEYPOINT_OKS_SIGMAS: []\n",
      "  PRECISE_BN:\n",
      "    ENABLED: False\n",
      "    NUM_ITER: 200\n",
      "VERSION: 2\n",
      "VIS_PERIOD: 0\n",
      "\u001b[32m[11/20 22:48:00 detectron2]: \u001b[0mFull config saved to ./outputfrcnn-r101/config.yaml\n"
     ]
    }
   ],
   "source": [
    "cfg = get_training_config(model=model, \n",
    "                          data_dir=data_dir, \n",
    "                          configs_dir=configs_dir, \n",
    "                          device=device, \n",
    "                          num_gpus=num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/20 22:48:09 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[11/20 22:48:09 d2.data.datasets.coco]: \u001b[0mLoaded 326 images in COCO format from ../data/hackathon/Ehu/Ehu_coco.json\n",
      "\u001b[32m[11/20 22:48:09 d2.data.datasets.coco]: \u001b[0mLoaded 1285 images in COCO format from ../data/hackathon/Gindai3/Gindai3_coco.json\n",
      "\u001b[32m[11/20 22:48:09 d2.data.datasets.coco]: \u001b[0mLoaded 157 images in COCO format from ../data/hackathon/Lehi/Lehi_coco.json\n",
      "\u001b[32m[11/20 22:48:09 d2.data.datasets.coco]: \u001b[0mLoaded 517 images in COCO format from ../data/hackathon/Lehi2/Lehi2_coco.json\n",
      "\u001b[32m[11/20 22:48:09 d2.data.datasets.coco]: \u001b[0mLoaded 1741 images in COCO format from ../data/hackathon/Onaga2/Onaga2_coco.json\n",
      "\u001b[32m[11/20 22:48:09 d2.data.datasets.coco]: \u001b[0mLoaded 721 images in COCO format from ../data/hackathon/Onaga3/Onaga3_coco.json\n",
      "\u001b[32m[11/20 22:48:09 d2.data.datasets.coco]: \u001b[0mLoaded 194 images in COCO format from ../data/hackathon/Girder/data-challenge-training-annotations/mouss_seq0_training.mscoco.oneclass.json\n",
      "\u001b[32m[11/20 22:48:09 d2.data.datasets.coco]: \u001b[0mLoaded 241 images in COCO format from ../data/hackathon/Girder/data-challenge-training-annotations/mouss_seq1_training.mscoco.oneclass.json\n",
      "\u001b[32m[11/20 22:48:09 d2.data.datasets.coco]: \u001b[0mLoaded 2543 images in COCO format from ../data/hackathon/Girder/data-challenge-training-annotations/afsc_seq0.mscoco.oneclass.json\n",
      "\u001b[32m[11/20 22:48:09 d2.data.datasets.coco]: \u001b[0mLoaded 740 images in COCO format from ../data/hackathon/Girder/data-challenge-training-annotations/mbari_seq0_training.mscoco.oneclass.json\n",
      "\u001b[32m[11/20 22:48:09 d2.data.datasets.coco]: \u001b[0mLoaded 80 images in COCO format from ../data/hackathon/US_SE_Quadcam_Sampler/JRS_1/JRS_1_coco.json\n",
      "\u001b[32m[11/20 22:48:09 d2.data.datasets.coco]: \u001b[0mLoaded 127 images in COCO format from ../data/hackathon/US_SE_Quadcam_Sampler/JRS_2/JRS_2_coco.json\n",
      "\u001b[32m[11/20 22:48:09 d2.data.datasets.coco]: \u001b[0mLoaded 236 images in COCO format from ../data/hackathon/US_SE_Quadcam_Sampler/JRS_3/JRS_3_coco.json\n",
      "\u001b[32m[11/20 22:48:09 d2.data.datasets.coco]: \u001b[0mLoaded 183 images in COCO format from ../data/hackathon/US_SE_Quadcam_Sampler/JRS_4/JRS_4_coco.json\n",
      "\u001b[32m[11/20 22:48:09 d2.data.datasets.coco]: \u001b[0mLoaded 232 images in COCO format from ../data/hackathon/US_SE_Quadcam_Sampler/JRS_5/JRS_5_coco.json\n",
      "\u001b[32m[11/20 22:48:09 d2.data.datasets.coco]: \u001b[0mLoaded 221 images in COCO format from ../data/hackathon/US_SE_Quadcam_Sampler/JRS_6/JRS_6_coco.json\n",
      "\u001b[32m[11/20 22:48:09 d2.data.datasets.coco]: \u001b[0mLoaded 495 images in COCO format from ../data/hackathon/US_SE_Quadcam_Sampler/JRS_7/JRS_7_coco.json\n",
      "\u001b[32m[11/20 22:48:09 d2.data.datasets.coco]: \u001b[0mLoaded 283 images in COCO format from ../data/hackathon/US_SE_Quadcam_Sampler/JRS_8/JRS_8_coco.json\n",
      "\u001b[32m[11/20 22:48:10 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|    FISH    | 38636        |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[11/20 22:48:10 d2.data.common]: \u001b[0mSerializing 10322 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/20 22:48:10 d2.data.common]: \u001b[0mSerialized dataset takes 3.69 MiB\n",
      "\u001b[32m[11/20 22:48:10 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[11/20 22:48:10 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[11/20 22:48:10 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from detectron2://COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl\n",
      "\u001b[32m[11/20 22:48:10 fvcore.common.file_io]: \u001b[0mURL https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl cached in /home/ubuntu/.torch/fvcore_cache/detectron2/COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl\n",
      "\u001b[32m[11/20 22:48:10 fvcore.common.checkpoint]: \u001b[0mReading a file from 'Detectron2 Model Zoo'\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/20 22:48:10 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/20 22:48:10 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/20 22:48:10 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/20 22:48:10 fvcore.common.checkpoint]: \u001b[0mSkip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "\u001b[32m[11/20 22:48:10 fvcore.common.checkpoint]: \u001b[0mSome model parameters or buffers are not found in the checkpoint:\n",
      "  \u001b[34mroi_heads.box_predictor.bbox_pred.{weight, bias}\u001b[0m\n",
      "  \u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[32m[11/20 22:48:10 d2.data.datasets.coco]: \u001b[0mLoaded 326 images in COCO format from ../data/hackathon/Ehu/Ehu_coco.json\n",
      "\u001b[32m[11/20 22:48:10 d2.data.datasets.coco]: \u001b[0mLoaded 1285 images in COCO format from ../data/hackathon/Gindai3/Gindai3_coco.json\n",
      "\u001b[32m[11/20 22:48:10 d2.data.datasets.coco]: \u001b[0mLoaded 157 images in COCO format from ../data/hackathon/Lehi/Lehi_coco.json\n",
      "\u001b[32m[11/20 22:48:10 d2.data.datasets.coco]: \u001b[0mLoaded 517 images in COCO format from ../data/hackathon/Lehi2/Lehi2_coco.json\n",
      "\u001b[32m[11/20 22:48:10 d2.data.datasets.coco]: \u001b[0mLoaded 1741 images in COCO format from ../data/hackathon/Onaga2/Onaga2_coco.json\n",
      "\u001b[32m[11/20 22:48:10 d2.data.datasets.coco]: \u001b[0mLoaded 721 images in COCO format from ../data/hackathon/Onaga3/Onaga3_coco.json\n",
      "\u001b[32m[11/20 22:48:10 d2.data.datasets.coco]: \u001b[0mLoaded 194 images in COCO format from ../data/hackathon/Girder/data-challenge-training-annotations/mouss_seq0_training.mscoco.oneclass.json\n",
      "\u001b[32m[11/20 22:48:10 d2.data.datasets.coco]: \u001b[0mLoaded 241 images in COCO format from ../data/hackathon/Girder/data-challenge-training-annotations/mouss_seq1_training.mscoco.oneclass.json\n",
      "\u001b[32m[11/20 22:48:10 d2.data.datasets.coco]: \u001b[0mLoaded 2543 images in COCO format from ../data/hackathon/Girder/data-challenge-training-annotations/afsc_seq0.mscoco.oneclass.json\n",
      "\u001b[32m[11/20 22:48:10 d2.data.datasets.coco]: \u001b[0mLoaded 740 images in COCO format from ../data/hackathon/Girder/data-challenge-training-annotations/mbari_seq0_training.mscoco.oneclass.json\n",
      "\u001b[32m[11/20 22:48:10 d2.data.datasets.coco]: \u001b[0mLoaded 80 images in COCO format from ../data/hackathon/US_SE_Quadcam_Sampler/JRS_1/JRS_1_coco.json\n",
      "\u001b[32m[11/20 22:48:10 d2.data.datasets.coco]: \u001b[0mLoaded 127 images in COCO format from ../data/hackathon/US_SE_Quadcam_Sampler/JRS_2/JRS_2_coco.json\n",
      "\u001b[32m[11/20 22:48:10 d2.data.datasets.coco]: \u001b[0mLoaded 236 images in COCO format from ../data/hackathon/US_SE_Quadcam_Sampler/JRS_3/JRS_3_coco.json\n",
      "\u001b[32m[11/20 22:48:10 d2.data.datasets.coco]: \u001b[0mLoaded 183 images in COCO format from ../data/hackathon/US_SE_Quadcam_Sampler/JRS_4/JRS_4_coco.json\n",
      "\u001b[32m[11/20 22:48:10 d2.data.datasets.coco]: \u001b[0mLoaded 232 images in COCO format from ../data/hackathon/US_SE_Quadcam_Sampler/JRS_5/JRS_5_coco.json\n",
      "\u001b[32m[11/20 22:48:10 d2.data.datasets.coco]: \u001b[0mLoaded 221 images in COCO format from ../data/hackathon/US_SE_Quadcam_Sampler/JRS_6/JRS_6_coco.json\n",
      "\u001b[32m[11/20 22:48:10 d2.data.datasets.coco]: \u001b[0mLoaded 495 images in COCO format from ../data/hackathon/US_SE_Quadcam_Sampler/JRS_7/JRS_7_coco.json\n",
      "\u001b[32m[11/20 22:48:10 d2.data.datasets.coco]: \u001b[0mLoaded 283 images in COCO format from ../data/hackathon/US_SE_Quadcam_Sampler/JRS_8/JRS_8_coco.json\n",
      "\u001b[32m[11/20 22:48:11 d2.data.common]: \u001b[0mSerializing 10322 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/20 22:48:11 d2.data.common]: \u001b[0mSerialized dataset takes 3.69 MiB\n",
      "\u001b[32m[11/20 22:48:11 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[11/20 22:48:11 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n"
     ]
    }
   ],
   "source": [
    "lr_finder = COCOLRFinder(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a8ac8dab8247cfbe0dd35b4ddcc746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/aifish/lib/python3.7/site-packages/detectron2/layers/wrappers.py:226: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  return x.nonzero().unbind(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 2.72E-04\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAA1JUlEQVR4nO3deVhV5fr/8ffNjICogIogiArOioIDag6VZlpZpqXNow3f8vSzebb5dOqcTnaarMzKNM2sTC2tnHIWNXFWnBAnQEUmmZ/fH+wMFRBwbzabfb+ua1+y13jvFe0Paz1rPY8YY1BKKeW8XOxdgFJKKfvSIFBKKSenQaCUUk5Og0AppZycBoFSSjk5DQKllHJybvYuoKoCAwNNixYt7F2GUko5lPXr16cZY4LKmudwQdCiRQvi4+PtXYZSSjkUETlQ3jy9NKSUUk5Og0AppZycBoFSSjk5h2sjUEpVXUFBAcnJyeTm5tq7FGVjXl5ehIaG4u7uXul1NAiUcgLJycn4+fnRokULRMTe5SgbMcZw/PhxkpOTiYiIqPR6emlIKSeQm5tLQECAhkAdJyIEBARU+cxPzwisJCO3gPUHTuLt7oqPhxv1PEv+DfLzxNVF/+dT9qch4Byq899Zzwis5O0FO7nz83WMnrSaq/+3nMv+vZReb/zOgLcXM3tDMkXFOu6DciDGwOrV8P33Jf/aaNyS//73v+Tk5Nhk25WVnp7OBx98UGP7a9GiBWlpaQD07t272tuZMmUKhw8ftkpNGgRWsnLPcXpENGLaPT355LZY3h0dzcvDO1Dfy53xMzdx5bvLWLD1KLYcCOhkdj6bk09RbKPQWb33OG8t2EF2XqFNtq9qifnzISwMBg2CO+4o+TcsrGS6ldWVICgsrN7/EytXrqz2Pq0ZBHppyArSsvJITMniySFt6d068Kx5t/QM5+ctR/n3wp3c99V6ujRvwLs3RtMi0Oei93vqdAFr9h5n1d7jrN57gh1HMzAGro1uxr9GdsHDzTo5b4zhi5X7eWXedoqKDQu3HuOjW2NoFeRrle2rWmT+fBg5Ek6fPnt6VlbJ9FmzYOjQKm82OzubG264geTkZIqKinj++ec5duwYhw8fZuDAgQQGBrJ48WIWLlzIiy++SF5eHq1ateLzzz/H19eX9evXM378eLKysggMDGTKlCkEBwczYMAAunTpwtKlSyksLGTy5Mn06NGD7OxsHn74YbZs2UJBQQETJkxg+PDhbN26lTvvvJP8/HyKi4v57rvveP7559mzZw/R0dEMGjSIt95666zaX3nlFaZOnUpQUBDNmzcnJiaGxx57jAEDBhAdHc3y5csZM2YMUVFRvPrqq+Tn5xMQEMDXX39NkyZNOH78OGPGjOHQoUPExcWd9cegr68vWVlZALz11lvMnDmTvLw8rrvuOl566SX279/PlVdeSd++fVm5ciUhISH8+OOPzJs3j/j4eG6++Wa8vb1ZtWoV3t7eVf/v/RdjjEO9YmJiTG0zP+GwCX9yrll/4ES5yxQUFpkZa5NMhxd+MQ9+vf6i95l8Msd0eWmBCX9yrol6dr656ZNVZuJvu8y/ftluwp+ca0Z/vMqk5+Rf9H7yCorMk7M2mfAn55q7p6w1C7YcMV1fXmg6vPCL+XnzkbOWTc/JN5/9sddc87/l5unZCSYtM/ei96+sY9u2bRdeqLjYmJAQY0ouBJX9Cg0tWa6KZs2aZe65554z79PT040xxoSHh5vU1FRjjDGpqanmkksuMVlZWcYYY/75z3+al156yeTn55u4uDiTkpJijDHmm2++MXfeeacxxpj+/fuf2e7SpUtNhw4djDHGPP300+arr74yxhhz8uRJExkZabKyssxDDz1kpk6daowxJi8vz+Tk5Jh9+/adWe9ca9euNV26dDGnT582GRkZpnXr1uatt946s+8HHnjgzLInTpwwxZZj88knn5jx48cbY4x5+OGHzUsvvWSMMWbu3LkGOPOZfXx8jDHGLFiwwNx7772muLjYFBUVmWHDhpmlS5eaffv2GVdXV7Nx40ZjjDGjRo0687n69+9v1q1bV2bdZf33BuJNOd+rekZgBWv2ncDb3ZWOzfzLXcbN1YUbujdnd0omn6/Yz9FTuTT196rW/owxPDN7M/mFxUy9uyfdIxri6eZ6Zn7rxr48MSuBUR+tZMqdPWjWoHp/KaRm5vHA1PXEHzjJQwNbM35QFC4uQocQfx6cup77p67ngQGtGNYpmK/XJPHDxkOcLiiibVM/Zq47yE+bDvOPyyK5La6F1c5OlA2tWQOnTlW8THo6rF0LPXtWadOdOnXi0Ucf5cknn+Sqq67ikksuOW+Z1atXs23bNvr06QNAfn4+cXFx7Ny5ky1btjBo0CAAioqKCA4OPrPemDFjAOjXrx8ZGRmkp6ezcOFC5syZw9tvvw2U3DWVlJREXFwcr732GsnJyYwYMYLIyMgK616xYgXDhw/Hy8sLLy8vrr766rPm33jjjWd+Tk5O5sYbb+TIkSPk5+efuX1z2bJlzJ49G4Bhw4bRsGHD8/azcOFCFi5cSNeuXQHIyspi9+7dhIWFERERQXR0NAAxMTHs37+/wpqrQ4PACtbsO0G38AaV+rK7pVc4ny7fx7S1SYwfFFWt/c3ecIilu1KZcHV7+kYGnjf/uq6hNPHz4r6v1nPdByuYOLor/vXcyc4rJCuviOy8QqKa+NG6cfmXdjYkneShrzdwIief98Z05eouzc7MC2ngzcz743jpp218uGQPHy7Zg5e7C8O7hHBrXDgdQ/xJTMnilbnbeHXedqatSeL5q9ozsG3jan1eVUOOHAGXC/wOu7hANa5LR0VFsWHDBubPn89zzz3HZZddxgsvvHDWMsYYBg0axPTp08+avnnzZjp06MCqVavK3Pa5d8mICMYYvvvuO9q0aXPWvHbt2tGzZ0/mzZvH0KFD+fjjj2nZsmWVP89ffHz+vsT78MMPM378eK655hqWLFnChAkTKr0dYwxPP/00991331nT9+/fj6en55n3rq6unD73sp0V6J9pF+lUTgE7jmbQMyKgUsuHB/gwsE1jpq1JIr+wuMr7S8nM5eW524gJb8htcS3KXa5360C+fSAOFxFunLSaIf/9g+s/XMXtk9fy4NcbGPLfZby9YCd5hUVnrVdcbPho6R5u+GgVLi7CrPt7nxUCf/F0c+X16zrx0S0xvDy8A2uevpw3R3amY0jJWVHrxr58cVcPPr+jOwB3TlnH6r3Hq/x5VQ0KDobiC/xOFhdDs/N/Hy7k8OHD1KtXj1tuuYXHH3+cDRs2AODn50dmZiYAvXr1YsWKFSQmJgIl7Qq7du2iTZs2pKamngmCgoICtm7dembbM2bMAGD58uX4+/vj7+/PFVdcwXvvvXfmevzGjRsB2Lt3Ly1btmTcuHEMHz6chISEs2o4V58+ffjpp5/Izc0lKyuLuXPnlvsZT506RUhICABffPHFmen9+vVj2rRpAPz888+cPHnyvHWvuOIKJk+efKa94NChQ6SkpFR4TCuqu6r0jOAirdt/AmOgR0SjSq9zW1w4d3y+jp+3HGF4dEiV9jdhzlZOFxTx5vWdcbnA8wltm9ZnzkN9WbYrFS93V3w8XfH1dMPL3ZXPV+znf4sT+WXrUf41sjPdwhqSlpXHozM3sXRXKkM7NeWNEZ3x9674MfUhHZtWOH9g28b0bNmI6Jd/5ddtx+jVsnKBqeygZ0/w9y9pGC5PgwbQo0eVN71582Yef/xxXFxccHd358MPPwRg7NixDBkyhGbNmrF48WKmTJnCmDFjyMvLA+DVV18lKiqKWbNmMW7cOE6dOkVhYSGPPPIIHTp0AEq6VOjatSsFBQVMnjwZgOeff55HHnmEzp07U1xcTEREBHPnzmXmzJl89dVXuLu707RpU5555hkaNWpEnz596NixI1deeeVZjcXdu3fnmmuuoXPnzjRp0oROnTrh71/2JeAJEyYwatQoGjZsyKWXXsq+ffsAePHFFxkzZgwdOnSgd+/ehIWFnbfu4MGD2b59O3FxcUBJI/LUqVNxdXU9b9m/3HHHHdx///21u7EYmAykAFvKmX8zkABsBlYCXSqz3drWWPzavG0m8pn55nR+YaXXKSoqNgPeWmyue395lfb18+aSRun/Ldpd1TLLtHjHMRP3+m+mxVNzzRPfbjLdX/3VRD4733y1av+ZRi9rueXT1ebyfy+x6jZV5VWqsdgYY+bNM8bbu+yGYm/vkvm1SEUNptaSmZlpjDEmOzvbxMTEmPXrL/5mD1uramOxLS8NTQGGVDB/H9DfGNMJeAWYZMNabGbN3uNEN2+Al3v5yX0uFxfh1l7hbEhKZ3PyBRrnLNJz8nnuh610aFafsf2qf02ztAFtGrNwfH9u6RnOjPiD+Hq58cODfbilV7jVn0LtFxnE7pQsjpyy/vVNZUVDh5bcIhoaCr6+UL9+yb+hodW+ddTRjR07lujoaLp168b1119Pt27d7F2S1dns0pAxZpmItKhgfuknKVYDobaqxVay8grZcjiDBwe0qvK618eE8vbCnXy5aj9vjepy3vy8wiISU7LYeTSTnUczWZ6YRnpOPl/c1R13V+vlt6+nG69c25E7+7Qg2N8bb4/KB1pVXBIVCPPhj91p3BDb3Cb7UFYydCgkJZXcHXT4cEmbQI8eUAu7qFiyZInN9/HX9f26rLa0EdwN/FzeTBEZC4wFyry+Zi8bDpykqNhUqX3gL/7e7lzXNYRv1yfzzNB2NPTxACDpeA7/WrCDX7YcpdDyhLCHmwuRjX157bqOdKjgFtWL0dLGD4e1aeJHkJ8ny3alahA4ApEq3yKqHJfdg0BEBlISBH3LW8YYMwnLpaPY2Nha02nPmn3HcXMRYsLPvy+4Mm6La8HXa5KYEX+Q0d2b896iRL5ctR83Fxdui2tBt/AGtG3qR4sAH9yseBZgDyLCJZGBLNqRQlGx0Y747MAYox3POQFTjW5s7BoEItIZ+BS40hjjcPcWrt13go4h/tTzqN5hbNPUj14tGzFp2V4+WJxIZl4hN8Q0Z/zgKJrUr97DZrVZ/6ggZm84xNbDp+gc2sDe5TgVLy8vjh8/rl1R13HGMh6Bl1fVvj/sFgQiEgbMBm41xuyyVx3VlVtQxKaDp7izb4uL2s49fVtyz5fx9I8K4umhbWnbtL51CqyF+lj6YVq2K1WDoIaFhoaSnJxMamqqvUtRNvbXCGVVYbMgEJHpwAAgUESSgRcBdwBjzEfAC0AA8IHlL5RCY0ysreqxto1J6eQXFdOzGu0DpV3evgnrnr2cID/PCy/s4AJ9PenQrD7Ldqfx0KUVP9qvrMvd3b1KI1Yp52LLu4bGXGD+PcA9ttq/ra3ZdxwRiG1xcUEAOEUI/KVfVBCfLNtLZm4Bfl6VH1NVKWU7jt0CaUdr952gfXB96uuXWZVcEhlIYbFh9d4T9i5FKWWhQVAN+YXFbEg6Wen+hdTfYsIb4u3uyh+79Vq1UrWFBkE1zNl0mNyC4mo9P+DsPN1ciWsVwLJdGgRK1RYaBFWQV1jEhDlbeezbTXQO9adf1PldQKsLuyQykP3Hc0g6bt8hCpVSJTQIKmlvahYjPljJlJX7uatPBN/eH1ft5wec3SWRQQD8kVi1s4KComLWHzjJ1NUHyNJxk5WyGqf9JsvJL+TLVQc4mZPPU0PaVviQzY9/HuKZ2Ztxd3Ph09tiubx9kxqstO5pFeRDM38vlu1K5eae4RUuuzc1iwVbj7Fq73Hi958gJ79k/IQFW48y+Q7r9ruklLNyuiDIKyxi2pok3l+8h7Sskj7Pm/l7c3vvFmUu/+u2Y/zjmz+JDW/IxDFdqz3so/qbiNAvKoh5CUfIzivEx7PsX8ODJ3IYOvEPcguKiWzsy8iYUHq1DCAtK48XftzKU99t5u1RnfVJWaUuktMEQWFRMbPWJzPx990cPpVLr5aN+PjWbvxvUSKvz99O71YBRDbxO2ud5JM5PPbtJjqG1GfqPT2r1NW0qtgN3ZszI/4gby3YyYRrOpw33xjD8z9uwVWExY8NICLQ56z5J7MLeOe3XYQ08GL84Dbnra+UqjynOa+etT6Zp2ZvJqi+F1Pv7sn0e3sRE96If43sgq+nG+O++fOsYRvzC4t5aNpGiosN79/UTUPAyrqFNeT2uBZ8sWo/8fvPf6bgly1HWbIzlfGD25wXAgDjLmvNjbHNmbgokW/WJtVEyUrVWU4TBNd2DeGz22P54cHe9I0MPHM5IcjPkzev78z2Ixn8Z+HfXR69+csO/jyYzpsjOxMecP4Xkbp4j1/Rhmb+3jzxXQK5BX+HcFZeIS/9tI32wfW5Pa7sNgQR4dXrOjKgTRDP/rCFxTsqHt9VKVU+pwkCL3dXLmvXpMzryZe3b8JNPcOY9MdeVu5JY+HWo3y2fB+3x4UztFOwHap1Dj6ebrwxohN7U7N59/fdZ6a/8+sujmXm8tp1HSvsftvd1YX3b+pGu2A/Hpq2gZPZ+TVRtlJ1jtMEwYU8N6wdEQE+jJ+xice+3USnEH+eGdbO3mXVef2ighgVE8qkZXvZcugUWw6d4vMV+7ipRxhdwy48zoOPpxtvj+pCdn4R3288VAMVK1X3aBBY1PNw47+jo0nLysMA79/UDU83bReoCc8Na08jHw8en5XAsz9soZGPB09c0bbS67dtWp8uof7MWHewWoNyKOXsNAhK6RzagMl3dOfre3oSFlDP3uU4Df967rwyvCPbj2Sw6WA6zw1rj3+9qnXmd2P3MHYey2RT8ikbValU3aVBcI5+UUE6aIodDOnYlNviwhke3Yzh0c2qvP7VXYLxdndlxrqDNqhOqbrNaZ4jULXfy8M7VntdPy93hnYK5qdNh3n+qnba/YdSVaBnBKrOGN2jOVl5hcxLOGLvUpRyKBoEqs6IDW9IyyAfvTykVBVpEKg6Q0S4MbY58ftPcHD+Ivj+e1i9GvROIqUqpBdSVZ0yOnUL13x4D40m5oCHGxQXQ4MG8PHHMHSovctTqlbSMwJVd8yfj/9tYwjOTMMzNwcyMiArC5KTYeRImD/f3hUqVStpEKi6wRgYOxZOny57/unTcN99eplIqTJoEKi6Yc0aOHWBh8nS02Ht2hopRylHokGg6oYjR8DlAr/OLi5w+HDN1KOUA9EgUHVDcHBJw3BFiouhWdWfWlaqrrNZEIjIZBFJEZEt5cxvKyKrRCRPRB6zVR3KSfTsCf7+FS/ToAH06FEj5SjlSGx5RjAFGFLB/BPAOOBtG9agnIUITJoE3uWMKe3tXXILqY5vrNR5bBYExphllHzZlzc/xRizDiiwVQ3KyQwdCrNmQWgo+PqS7+NLlrsXBcHNSqbrcwRKlckhHigTkbHAWICwsDA7V6NqtaFDISkJ1q4lZ89+7vjlEIPuuJr/uzTS3pUpVWs5RGOxMWaSMSbWGBMbFBRk73JUbScCPXvS4KYbKereg0U7U+1dkVK1mkMEgVLVNbBtYzYmndTxjJWqgAaBqtMubduYYgNLd+lZgVLlsVkbgYhMBwYAgSKSDLwIuAMYYz4SkaZAPFAfKBaRR4D2xpgMW9WknE/nEH8CfDxYtCOFa7uG2LscpWolmwWBMWbMBeYfBUJttX+lAFxchP5tgvh9ewpFxQZXF719VKlz6aUhVedd2rYxp04XsDHppL1LUapW0iBQdd4lkUG4ugiLdqTYuxSlaiUNAlXn+Xu7ExveUINAqXJoECincGnbxuw4msnh9HLGK1DKiWkQKKcwsG1jABbv1LMCpc6lQaCcQmRjX1oG+jAzPhmjo5QpdRYNAuUURIQ7+0aw6WA66/br3UNKlaZBoJzGyG6hNPLxYNKyPfYuRalaRYNAOQ1vD1du7RXOb9tTSEzJsnc5StUaGgTKqdwWF46nmwuf/rHX3qUoVWtoECinEuDryciYUGZvOERKZq69y1GqVtAgUE7nnktaUlBczJcrD9i7FKVqBQ0C5XQiAn0Y3L4JX60+QHZeob3LUcruNAiUUxrbryWnThfwbfxBe5eilN1pECinFBPeiJjwhny6fB+FRcX2Lkcpu9IgUE7r3ktaknzyNFe9t5zPlu8jLSvP3iUpZRcaBMppXdGhCW9e3wlPNxdembuNXq//zr1fxrNE+yNSTkYcrd+V2NhYEx8fb+8yVB2z61gm361PZvbGQ6Rm5vHBzd0Y2inY3mUpZTUist4YE1vWPD0jUAqIauLH00PbseLJS+ka1oAnZiWwPy3b3mUpVSM0CJQqxcPNhf/d1A03V+GBrzeQW1Bk75KUsjkNAqXOEdLAm3duiGb7kQxe+mmrvctRyuY0CJQqw8C2jXlwQCumrz3I7A3J9i5HKZvSIFCqHOMHRdEjohHPfr+F3ccy7V2OUjajQaBUOdxcXXhvTFd8PF159NtNOrKZqrNsFgQiMllEUkRkSznzRUQmikiiiCSISDdb1aJUdTWp78Ujl0eRkHyKzYdO2bscpWzClmcEU4AhFcy/Eoi0vMYCH9qwFqWqbXh0M7zdXZm+VvslUnWTzYLAGLMMOFHBIsOBL02J1UADEdEneFSt4+flzrDOwcz585D2VqrqJHu2EYQApf/ESrZMU6rWGdOjOdn5RcxLOGLvUpSyOodoLBaRsSISLyLxqamp9i5HOaFuYQ1p3diX6euS7F2KUlZnzyA4BDQv9T7UMu08xphJxphYY0xsUFBQjRSnVGkiwujuzdmYlM7Oo3orqapb7BkEc4DbLHcP9QJOGWP0vFvVWiO6heLh6sI3elag6hhb3j46HVgFtBGRZBG5W0TuF5H7LYvMB/YCicAnwIO2qkUpa2jk48HgDk34fuMh7YNI1SluttqwMWbMBeYb4P9stX+lbGF09zDmJhxhwdajDI/WextU3eAQjcVK1Ra9WwXQvJE33+gzBaoO0SBQqgpcXITR3cNYtfe4jleg6gwNAqWqaGRMKK4uwox4PStQdYMGgVJV1KS+FwOigpi9IZmiYu2ITjk+DQKlqmFUbCjHMvJYtlsfcFSOT4NAqWq4tG0TGtZzZ1a8DlqjHJ8GgVLV4OHmwvDoEH7ddoz0nHx7l6PURalUEIiIj4i4WH6OEpFrRMTdtqUpVbuNig0lv6iYOZsO27sUpS5KZc8IlgFeIhICLARupWS8AaWcVodm/rQPrs+3enlIObjKBoEYY3KAEcAHxphRQAfblaWUYxgVG8rmQ6fYcTTD3qUoVW2VDgIRiQNuBuZZprnapiSlHMfw6BDcXUXPCpRDq2wQPAI8DXxvjNkqIi2BxTarSikH0cjHg8vbNeGHjYcoKCq2dzlKVUulgsAYs9QYc40x5k1Lo3GaMWacjWtTyiGMjAnleHY+i3ek2LsUpaqlsncNTROR+iLiA2wBtonI47YtTSnH0D8qiCA/T75dr5eHlGOq7KWh9saYDOBa4GcggpI7h5Ryem6uLozoGsLiHSmkZeXZuxylqqyyQeBueW7gWmCOMaYA0E5WlLIYGRNKYbHhJ32mQDmgygbBx8B+wAdYJiLhgN4vp5RFZBM/2jb1Y26CjraqHE9lG4snGmNCjDFDTYkDwEAb16aUQ7m6SzPWHzjJ4fTT9i5FqSqpbGOxv4j8R0TiLa9/U3J2oJSyuKpzMADz9KxAOZjKXhqaDGQCN1heGcDntipKKUcUHuBDpxB/5iZoO4FyLJUNglbGmBeNMXstr5eAlrYsTClHdFXnYDYlnyLpeI69S1Gq0iobBKdFpO9fb0SkD6AXQpU6xzDL5aG5m/WsQDmOygbB/cD7IrJfRPYD/wPus1lVSjmo0Ib16BrWgJ82aTuBchyVvWtokzGmC9AZ6GyM6QpcatPKlHJQV3VuxvYjGexJzbJ3KUpVSpVGKDPGZFieMAYYb4N6lHJ4wzoFIwJz9axAOYiLGapSLriAyBAR2SkiiSLyVBnzw0XkdxFJEJElIhJ6EfUoVSs09feie3gjvXtIOYyLCYIKu5gQEVfgfeBKoD0wRkTan7PY28CXxpjOwMvAGxdRj1K1xlVdgtmdksXOo5n2LkWpC6owCEQkU0QyynhlAs0usO0eQKLldtN84Btg+DnLtAcWWX5eXMZ8pRzSlR2DcRH0rEA5hAqDwBjjZ4ypX8bLzxjjdoFthwAHS71PtkwrbRMlw18CXAf4iUjAuRsSkbF/PdWcmpp6gd0qZX9Bfp70ahnA3IQjGKP9M6ra7WIuDVnDY0B/EdkI9AcOAUXnLmSMmWSMiTXGxAYFBdV0jUpVy/DoZuxLy2aRDlijajlbBsEhoHmp96GWaWcYYw4bY0ZYbkd91jIt3YY1KVVjrusaSssgH16Zu438Qh3GUtVetgyCdUCkiESIiAcwGphTegERCbQMfQklYyJPtmE9StUoDzcXXriqPfuP5/D5in32LkepctksCIwxhcBDwAJgOzDTMvD9yyJyjWWxAcBOEdkFNAFes1U9StnDgDaNuaxtY95blEhKZq69y1GqTOJoDVmxsbEmPj7e3mUoVWn70rIZ/M5ShkeH8PaoLvYuRzkpEVlvjIkta569G4uVqvMiAn24q28Es9Yn8+fBdHuXo9R5NAiUqgEPXxpJkJ8nE+ZspbjYsc7CVd2nQaBUDfD1dOPJIW3582A63288dOEVlKpBGgRK1ZARXUOIbt6AtxfupKBIbydVtYcGgVI1xMVFGHdZa46cyuXnLUftXY5SZ2gQKFWDBkQ1pmWgD58t36ddT6haQ4NAqRrk4iLc2acFmw6msyEp3d7lKAVoEChV40Z0C6W+lxuT7fS0cXGx4VC6Djmu/qZBoFQN8/F0Y0yPMH7ZcrTGv5CLiw1PfJdAn38u4vuNyTW6b1V7aRAoZQe39W4BwJcr99fYPo0xvDBnC7PWJ9O0vhdPfreZTfqAm0KDQCm7CGngzZCOTZm+NonsvEKb788Yw2vztjN1dRL39W/JvHF9aeznydiv4jmWoX0gOTsNAqXs5K4+EWTkFjJ7g+0v0bzz6y4+Xb6P2+PCeWpIWwJ8PfnktlgycwsZ+9V6cgvOGwZEORENAqXspFtYA7o0b8DnK/bbtNuJD5YkMnFRIqO7N+fFqzsgIgC0C67Pf26IZtPBdJ6ZvVlvZ3ViGgRK2YmIcFefFuxNy2bJLtuMYrZ0Vyr/+mUnw6Ob8dp1nXBxkbPmD+nYlP93eRSzNx7i0z90zARnpUGglB0N7RRMM38vXpu3nZx867YVZOYW8PR3CbRu7Mu/RnbG9ZwQ+MvDl7bm8nZNeHvhTjJzC6xag3IMGgRK2ZG7qwtvjerC3rRsXvxxq1W3/eYvOziSkcu/RnbG08213OVcXIQHBrQkr7CYhVuPWbUG5Rg0CJSysz6tA3l4YGu+XZ9stXv7V+05ztTVSdzdJ4JuYQ0vuHy3sIaENvTmhz+1Z1RnpEGgVC0w7rJIerRoxLPfb2FvatZFbSsnv5Anv0sgPKAejw5uU6l1RITh0c1YkZimQ2o6IQ0CpWoBN1cX3h0TjaebC/83beNF3c7574W7SDqRw5vXd8bbo/xLQue6NjqEYgNzNx2p9r6VY9IgUKqWCPb35t83dGH7kQxen7+9WtvYkHSSySv2cUuvMHq1DKjSupFN/GgfXJ8fNx2u1r6V49IgUKoWubRtE+7pG8GXqw4wf3PV/jJPzcxj/Iw/aebvzVNXtqvW/q/t2oxNB9PZl5ZdrfWVY9IgUKqWeWJIW7qGNeCJWQmVbi84lVPArZ+t4VhGHhPHROPr6VatfV/dpRki8KM2GjsVDQKlahkPNxfev6kbHm4uPDB1wwWfL8jOK+SOKWvZm5rNpNtiiAlvVO19B/t70zOiET/+eVifNHYiGgRK1ULNGnjz7uhodqVk8uz3W8r9Us4tKGLsV/EkJJ9i4piuXBIZdNH7vjY6hH1p2SQkn7robSnHoEGgVC11SWQQj1wWxfcbD/H1mqTz5hcUFfPQtI2sSDzOWyM7M6RjU6vs98pOwXi4uvDjn9po7CxsGgQiMkREdopIoog8Vcb8MBFZLCIbRSRBRIbash6lHM3Dl7amf1QQL/+0jYTkdE5k5zMv4QjPfr+Zy/+zlN+2H+OV4R0Y0S3Uavv093ZnYNsgfko4TJENO8NTtUf1WpQqQURcgfeBQUAysE5E5hhjtpVa7DlgpjHmQxFpD8wHWtiqJqUcjYuL8N8bo7nqveXc8PEqcguKAfD1dKNnRCMeHdyGa7o0s/p+r40OYcHWY6zck2aVy02qdrNZEAA9gERjzF4AEfkGGA6UDgID1Lf87A/ouahS52jo48HHt8Yw8ffddGnegN6tAugU4o+bq+1O6Ae2bYyfpxvT1iRpEDgBWwZBCHCw1PtkoOc5y0wAForIw4APcHlZGxKRscBYgLCwMKsXqlRt1zHEn0m3xdbY/rzcXbmrbwTv/r6bpbtS6R+lYVCX2buxeAwwxRgTCgwFvhKR82oyxkwyxsQaY2KDgvQXUqma8MCAVrQM9OG5HzZzOl9HMKvLbBkEh4Dmpd6HWqaVdjcwE8AYswrwAgJtWJNSqpK83F157bpOHDxxmomLdtu7HGVDtgyCdUCkiESIiAcwGphzzjJJwGUAItKOkiBItWFNSqkqiGsVwMiYUD5ZtpcdRzPsXY6yEZsFgTGmEHgIWABsp+TuoK0i8rKIXGNZ7FHgXhHZBEwH7jD6OKNStcozQ9vh5+XGM7M323RsZWU/tmwsxhgzn5JbQktPe6HUz9uAPrasQSl1cRr5ePDcsPY8+u0mpq1N4pZe4fYuSVmZvRuLlVIOYES3EOJaBvDmLzs4lqED19Q1GgRKqQsSEV67riMFRcXc9tla0rLy7F2SsiINAqVUpbQM8mXy7d1JOpHD6EmrSdEzgzpDg0ApVWm9Wwfy+Z3dOZx+mtGTVnP0lIZBXaBBoJSqkl4tA/jirh4cy8jlxkmrOJx+2t4lqYukQaCUqrLuLRrx5d09OZGVz42TVpGaqW0GjkyDQClVLTHhDfny7h6kZOTxyIyN2mW1A9MgUEpVW9ewhrwyvCMrEo8z8XfthsJRaRAopS7KqNhQru8WysRFu1m2S3uIcUQaBEqpiyIivHptR6Ia+/HIjD/1TiIHpEGglLpo3h6uvH9zN/IKinho2gYKiortXZKqAg0CpZRVtG7sy+sjOhF/4CRvL9hZ5fXXHzjJVe/9wa/bjtmgOlURDQKllNUMjw5hTI8wJv2xl22HK99tdWZuAf/4ZiNbDmVw75fxvDp3G/mFelZRUzQIlFJW9dSQtvh7u/P6/O1Utlf5V+Zu43D6aabd05Pb48L5dPk+Rn28ioMncmxcrQINAqWUlfnXc2fcpZEsT0xjyc4L30W0YOtRZsYn88CAVvRuHchLwzvywc3d2JuSxbCJfzBn02F9RsHGNAiUUlZ3S69wIgJ9eG3+dgoraDhOzczj6dmb6dCsPv+4LOrM9KGdgpk37hJaBPowbvpGLnlzEf/9bZd2Z2EjGgRKKavzcHPhqSvbkpiSxTfrDpa5jDGGp75LICuvkHdujMbD7eyvo7CAenz3QG8+vLkbrRr78u7vu+n75iLu/HwtcxMOk51XWBMfxSnYdIQypZTzGty+CT0iGvHOr7sYHt0MPy/3s+bPWHeQ33ek8PxV7Ylq4lfmNtxdXbiyUzBXdgrm4IkcZqw7yMz4gyzeuREPNxf6RQYxpGNTLm/XmAb1PGriY9VJekaglLIJEeG5Ye04np3PB0v2nJm+82gmT32XwAs/bqV3qwDu7N2iUttr3qgej13RhlVPX8Y3Y3txU48wth0+xWPfbiLm1d/4atV+m3yOQ+mnufnT1SSmZNpk+7WBnhEopWymc2gDrusawmfL99Ey0Icf/jzEisTjeLq5cH1MCI8OboOLi1Rpm64uQq+WAfRqGcCLV7dn86FTvL1wFy/O2Up4gA/9ooKs+hl+2FhS831frefHh/ri61n3vjb1jEApZVOPX9EGAR6flcDe1GyeGNKG1U9fxhsjOhPo63lR2xYROoc24IObuxHZ2I+Hpm1gX1p2mcsaY8gtKKryPn7ddowm9T3Zl5bNU98lVPqWWEeiQaCUsqlmDbyZdFss79/UjWVPDOTBAa1p6GPd6/m+nm58enssri7CPV+sIyO34Kz52w5ncN0HK+n5+u9sTDpZ6e2mZOby58F0bukZzuNXtGVuwhGmrNxv1dprAw0CpZTN9Y8KYljnYNxdbfeV07xRPT64OYYDx3MYN71kfITsvEJem7eNq/+3nIMncvDzcuPWz9aybv+JSm3z9+0pAFzevgn392/JoPZNeG3edtYfqNz6jkKDQClVZ8S1CmDCNR1YsjOVcdM3Mug/S/nkj33cEBvK74/2Z9b9vWlc35PbPlvLisS0C27vt23HCG3oTdumfogIb4/qQkhDbx78egNpWXVnVDabBoGIDBGRnSKSKCJPlTH/HRH50/LaJSLptqxHKVX33dIrnFt7hTNv8xHqe7vz3QNxvDGiMw3qedDU34sZY+MIa1SPO6esY/HOlHK3k5NfyPLENC5v1wSRkgZtf293Prw5hvScAh6eVndGZbNZEIiIK/A+cCXQHhgjIu1LL2OM+X/GmGhjTDTwHjDbVvUopZzHi1e3Z9o9Pfnp4b7EhDc6a16QnyfTx/YisrEvY7+M5/ftZfd2+sfuNPIKixncvslZ09s3q8+r13Zk1d7jvPvbLpt9hppkyzOCHkCiMWavMSYf+AYYXsHyY4DpNqxHKeUk3Fxd6N06sNw2iUY+Hky7pxdtmvrx6LebSM/JP2+ZX7cdo76XG90jGp03b1Rsc0bFhPLe4sQKR2U7cDzbIXpRtWUQhAClny1Ptkw7j4iEAxHAIhvWo5RSZ/jXc+etkV3IOF3AO7+e/Zd9UbFh0Y4UBrZtXG6YvDy8/FHZjDF8tHQPA95ewstzt9rsM1hLbWksHg3MMsaUeZOviIwVkXgRiU9N1TFRlVLW0S64Pjf1DGPqmiR2Hv37yeENSSc5kZ3PoHMuC5X216hsuQVFjJu+8UznerkFRfy/GX/yz5930KieBzPjk0nNrN0Ny7YMgkNA81LvQy3TyjKaCi4LGWMmGWNijTGxQUHWfWpQKeXcHh3UBl9PN176aeuZh8V+23YMd1eh/wWeUm7d2JfXr+vE2v0n+Pevuzh6KpcbPl7FD38e5rHBUcy8P46ComK+qOXPHtgyCNYBkSISISIelHzZzzl3IRFpCzQEVtmwFqWUKlNDHw8eHRzFyj3HWbD1KFDSPtCrZcB5HeWV5dquJaOyfbhkD0Mn/sGelCwm3RrDQ5dG0irIl8Htm/Dlqv21urdUmwWBMaYQeAhYAGwHZhpjtorIyyJyTalFRwPfmLr43LZSyiHc1COMtk39eHXedrYePsXetOwKLwud68Wr29MpxB9fTzdmP9iHwR2anpl3X/9WZOQWltsdd20gjvb9Gxsba+Lj4+1dhlKqjlm5J42bPllDeEA9DhzPYeVTl9KsgXel188vLMZFSu5YOtcNH63iUPppljw+wKZPV1dERNYbY2LLmldbGouVUsquercKZGinphw4nkPHkPpVCgEoGYynrBAAuK9/Sw6ln2ZewhFrlGp1GgRKKWXxzNB2+Hi4MqxTM6tud2CbxkQ29uWjpXtqZe+lGgRKKWUR2rAeK5+6jLH9Wlp1uy4uwth+LdlxNJNlu//u4ygnv5C5CYeZvjbJrt1V1L0RFpRS6iL417vwnULVMTw6hLcX7uSDxYnk5BUyd/MRFm1P4bRljITlu9PKHLu5JmgQKKVUDfBwc+HuvhG8Pn8Ha/adIMDHg+tjQhjWqRlbDp3itfnbycor5KNbYvD2cK3R2jQIlFKqhtzaqwWFxYbo0Ab0iGh0pnE5rlUAfl5uPP39Zm6fvJZP74ilfiWeYbAWbSNQSqka4u3hyoMDWtO7deB5dxiN7hHGe2O6siHpJDd9sprjNTjegQaBUkrVEld1bsYnt8Wy+1gWN3+65rwhN21Fg0AppWqRgW0b8+ntsSSmZPHg1A0UFNm+G2sNAqWUqmUuiQzijRGdWJ6YxtOzN9v82QNtLFZKqVpoVGxzkk+e5t3fd9O8YT3+cXmkzfalQaCUUrXUI5dHknzyNO/8touQht6MjAm1yX40CJRSqpYSEd4Y0YmjGad56rsEgv296NM60Or70TYCpZSqxTzcXPjwlhhaN/Zl2+EMm+xDzwiUUqqWq+/lzg//1wcvd9s8caxnBEop5QBsFQKgQaCUUk5Pg0AppZycBoFSSjk5DQKllHJyGgRKKeXkNAiUUsrJaRAopZSTE1v3amdtIpIKHDhnsj9wqorTAoE0bK+sOqy97oWWq2h+dY5dedNq4pg64vEsa7oez8rN1+NZ9eXKmx9ujAkqcw1jjMO/gElVnQbE26s2a697oeUqml+dY1fetJo4po54PMs5Vno89XjW+PEs71VXLg39dBHTbO1i9lnZdS+0XEXzL+bY6fGs/Lxzp+vxrNx8PZ5VX67KNTjcpSFrEZF4Y0ysveuoS/SYWpceT+vS41m+unJGUB2T7F1AHaTH1Lr0eFqXHs9yOO0ZgVJKqRLOfEaglFIKDQKllHJ6GgRKKeXkNAjKICIDROQPEflIRAbYu566QER8RCReRK6ydy2OTkTaWX43Z4nIA/aux9GJyLUi8omIzBCRwfauxx7qXBCIyGQRSRGRLedMHyIiO0UkUUSeusBmDJAFeAHJtqrVEVjpeAI8Ccy0TZWOwxrH0xiz3RhzP3AD0MeW9dZ2VjqePxhj7gXuB260Zb21VZ27a0hE+lHyJf6lMaajZZorsAsYRMkX+zpgDOAKvHHOJu4C0owxxSLSBPiPMebmmqq/trHS8ewCBFASrGnGmLk1U33tY43jaYxJEZFrgAeAr4wx02qq/trGWsfTst6/ga+NMRtqqPxao84NXm+MWSYiLc6Z3ANINMbsBRCRb4Dhxpg3gIouVZwEPG1SqIOwxvG0XF7zAdoDp0VkvjGm2JZ111bW+v00xswB5ojIPMBpg8BKv58C/BP42RlDAOpgEJQjBDhY6n0y0LO8hUVkBHAF0AD4n00rc0xVOp7GmGcBROQOLGdbNq3O8VT193MAMIKSP1Lm27IwB1Wl4wk8DFwO+ItIa2PMR7YsrjZyliCoEmPMbGC2veuoa4wxU+xdQ11gjFkCLLFzGXWGMWYiMNHeddhTnWssLschoHmp96GWaap69Hhalx5P69LjWUXOEgTrgEgRiRARD2A0MMfONTkyPZ7WpcfTuvR4VlGdCwIRmQ6sAtqISLKI3G2MKQQeAhYA24GZxpit9qzTUejxtC49ntalx9M66tzto0oppaqmzp0RKKWUqhoNAqWUcnIaBEop5eQ0CJRSyslpECillJPTIFBKKSenQaDqDBHJquH9razh/TUQkQdrcp/KOWgQKFUOEamwLy5jTO8a3mcDQINAWZ0GgarTRKSViPwiIusto861tUy/WkTWiMhGEfnNMvYEIjJBRL4SkRXAV5b3k0VkiYjsFZFxpbadZfl3gGX+LBHZISJfW7o2RkSGWqatF5GJInLeWAwicoeIzBGRRcDvIuIrIr+LyAYR2Swiwy2L/hNoJSJ/ishblnUfF5F1IpIgIi/Z8liqOswYoy991YkXkFXGtN+BSMvPPYFFlp8b8veT9fcA/7b8PAFYD3iXer+Ski6fA4HjgHvp/QEDgFOUdG7mQkmXB30pGYjnIBBhWW46MLeMGu+gpKvkRpb3bkB9y8+BQCIgQAtgS6n1BgOTLPNcgLlAP3v/d9CX4720G2pVZ4mIL9Ab+NbyBzr8PdBQKDBDRIIBD2BfqVXnGGNOl3o/zxiTB+SJSArQhPOHMF1rjEm27PdPSr60s4C9xpi/tj0dGFtOub8aY078VTrwumX0rWJK+tdvUsY6gy2vjZb3vkAksKycfShVJg0CVZe5AOnGmOgy5r1HyTCkcywDvUwoNS/7nGXzSv1cRNn/31RmmYqU3ufNQBAQY4wpEJH9lJxdnEuAN4wxH1dxX0qdRdsIVJ1ljMkA9onIKCgZklBEulhm+/N3H/W326iEnUDLUkMpVnZgdH8gxRICA4Fwy/RMwK/UcguAuyxnPohIiIg0vviylbPRMwJVl9QTkdKXbP5DyV/XH4rIc4A78A2wiZIzgG9F5CSwCIiwdjHGmNOW2z1/EZFsSvrJr4yvgZ9EZDMQD+ywbO+4iKwQkS2UjK/7uIi0A1ZZLn1lAbcAKdb+LKpu026olbIhEfE1xmRZ7iJ6H9htjHnH3nUpVZpeGlLKtu61NB5vpeSSj17PV7WOnhEopZST0zMCpZRychoESinl5DQIlFLKyWkQKKWUk9MgUEopJ6dBoJRSTu7/A+2a2OrFiP5KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_finder.range_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aifish",
   "language": "python",
   "name": "aifish"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
